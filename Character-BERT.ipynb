{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0ZOWM_6cDWq",
    "outputId": "57f188da-7556-49f9-f705-1f2f3f1c861b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 12.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (1.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 60.6MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0MB 56.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (4.41.1)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 57.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (20.8)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.3.1) (0.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.3.1) (1.0.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.3.1) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.3.1) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1bb0679af0d6e7f16baef4d9a5978a476c8e2747f7abd77499dd7b0036a5b0a0\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bb3qsWMGcPEm",
    "outputId": "ee7cc1a2-c0b5-43ac-f76e-35180e024d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'character-bert'...\n",
      "remote: Enumerating objects: 51, done.\u001b[K\n",
      "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
      "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
      "remote: Total 51 (delta 12), reused 31 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (51/51), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/helboukkouri/character-bert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-Gzt0ORcWuW",
    "outputId": "ef3496d4-49ea-449a-f4cc-578b9c1d57af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/character-bert\n"
     ]
    }
   ],
   "source": [
    "%cd character-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s03cp9sueDLZ",
    "outputId": "60290d2f-935c-4fae-8f15-6bdf8a06d185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/12/2020 12:33:05 - INFO - download.py -   Downloading medical_character_bert model (~200MB tar.xz archive)\n",
      "21/12/2020 12:33:09 - INFO - download.py -   Extracting model from archive (~420MB folder)\n",
      "21/12/2020 12:33:22 - INFO - download.py -   Removing archive\n",
      "21/12/2020 12:33:22 - INFO - download.py -   Done.\n"
     ]
    }
   ],
   "source": [
    "!python download.py --model='medical_character_bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYfpR4nLSfeg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
    "from modeling.character_bert import CharacterBertModel\n",
    "from utils.character_cnn import CharacterIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMg9oHuFSpEL"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time / 60)\n",
    "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "  return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVIPxmAzTQcB"
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-uncased', num_labels=6) \n",
    "model = BertForSequenceClassification(config=config)\n",
    "character_bert_model = CharacterBertModel.from_pretrained(\n",
    "    './pretrained-models/medical_character_bert/')\n",
    "model.bert = character_bert_model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model.cuda()\n",
    "device='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra7JIPG7Sus5"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset.csv')\n",
    "df_train['sentiment'], uniq = pd.factorize(df_train['sentiment'])\n",
    "X = df_train['comment'].tolist()\n",
    "tokenized = [tokenizer.basic_tokenizer.tokenize(text) for text in X]\n",
    "indexer = CharacterIndexer()  # This converts each token into a list of character indices\n",
    "input_tensor = indexer.as_padded_tensor(tokenized)\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_tensor,df_train['sentiment'].tolist(),test_size=0.1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JrdayfTgS-sK"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "y_train, y_test = torch.tensor(y_train), torch.tensor(y_test)\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_data,batch_size=batch_size)\n",
    "\n",
    "val_data = TensorDataset(X_test, y_test)\n",
    "val_dataloader = DataLoader(val_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5yzscrxT8sP"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = AdamW(optimizer_grouped_parameters,lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWMejym6T_Xh",
    "outputId": "1fce0e7b-5bdc-4e36-c269-63837c5c32e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [03:51<07:43, 231.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 51)\n",
      "\n",
      "Train loss: 1.0491705411817969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 2/3 [07:44<03:52, 232.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 53)\n",
      "\n",
      "Train loss: 0.8557209728694544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [11:37<00:00, 232.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 52)\n",
      "\n",
      "Train loss: 0.7482494985185019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "train_loss_set = []\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "  start_time = time.time()\n",
    "  model.train()\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    b_input_ids, b_labels = batch\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    outputs = model(b_input_ids)[0]\n",
    "    \n",
    "    loss = loss_fn(outputs,b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "  end_time = time.time()\n",
    "\n",
    "  print(epoch_time(start_time,end_time))\n",
    "\n",
    "  print(\"\\nTrain loss: {}\".format(tr_loss/nb_tr_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJj5x7m8UK73"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  for i, batch in enumerate(val_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    b_input_ids, b_labels = batch\n",
    "    \n",
    "    outputs = model(b_input_ids)[0]\n",
    "    # print (outputs)\n",
    "    prediction = torch.argmax(outputs,dim=1)\n",
    "    preds.append(prediction)\n",
    "    total += b_labels.size(0)\n",
    "    correct+=(prediction==b_labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR3qRTewXg8d"
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for tensor in preds:\n",
    "  for pred in tensor:\n",
    "    final_preds.append(int(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84SA7KTCXj6Z",
    "outputId": "7a961f40-5eb8-4e62-fbf5-c077befcb90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       154\n",
      "           1       0.75      0.86      0.80       407\n",
      "           2       0.72      0.60      0.65        82\n",
      "           3       0.43      0.30      0.35        44\n",
      "           4       0.00      0.00      0.00        27\n",
      "           5       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.72       728\n",
      "   macro avg       0.43      0.41      0.42       728\n",
      "weighted avg       0.67      0.72      0.69       728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXnvlW1_X4T5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "STLKanSen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
